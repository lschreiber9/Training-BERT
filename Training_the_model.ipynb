{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMNOMNwBlSPhbwYuqBucwGL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lschreiber9/Training-BERT/blob/main/Training_the_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "mv21pecJLyAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets"
      ],
      "metadata": {
        "id": "DnGcyICSNT2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "datasets = {\n",
        "    \"climate_specificity\": {\n",
        "        \"train\": \"hf://datasets/climatebert/climate_specificity/data/train-00000-of-00001-298fad749f8929f7.parquet\",\n",
        "        \"test\": \"hf://datasets/climatebert/climate_specificity/data/test-00000-of-00001-2588e03729a1bfe7.parquet\"\n",
        "    },\n",
        "    \"climate_sentiment\": {\n",
        "        \"train\": \"hf://datasets/climatebert/climate_sentiment/data/train-00000-of-00001-04b49ae22f595095.parquet\",\n",
        "        \"test\": \"hf://datasets/climatebert/climate_sentiment/data/test-00000-of-00001-3f9f7af4f5914b8e.parquet\"\n",
        "    },\n",
        "    \"climate_commitments_actions\": {\n",
        "        \"train\": \"hf://datasets/climatebert/climate_commitments_actions/data/train-00000-of-00001-2044cce9e261c6b3.parquet\",\n",
        "        \"test\": \"hf://datasets/climatebert/climate_commitments_actions/data/test-00000-of-00001-77f76c0960abb9c6.parquet\"\n",
        "    },\n",
        "    \"environmental_claims\": {\n",
        "        \"train\": \"hf://datasets/climatebert/environmental_claims/data/train-00000-of-00001-98aa5228a06a17d0.parquet\",\n",
        "        \"validation\": \"hf://datasets/climatebert/environmental_claims/data/validation-00000-of-00001-2553e47d408fab28.parquet\",\n",
        "        \"test\": \"hf://datasets/climatebert/environmental_claims/data/test-00000-of-00001-79fd931297fff765.parquet\"\n",
        "    },\n",
        "    \"climate_detection\": {\n",
        "        \"train\": \"hf://datasets/climatebert/climate_detection/data/train-00000-of-00001-4b831beb8839bf3e.parquet\",\n",
        "        \"test\": \"hf://datasets/climatebert/climate_detection/data/test-00000-of-00001-87f8706e009e9b75.parquet\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to load data for a specific dataset\n",
        "def load_data(dataset_name):\n",
        "    if dataset_name not in datasets:\n",
        "        raise ValueError(f\"Dataset '{dataset_name}' is not defined.\")\n",
        "\n",
        "    dataset_info = datasets[dataset_name]\n",
        "    train_df = pd.read_parquet(dataset_info[\"train\"])\n",
        "    test_df = pd.read_parquet(dataset_info[\"test\"])\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Load data for each dataset and assign variables dynamically\n",
        "for dataset_name in datasets.keys():\n",
        "    globals()[f\"train_{dataset_name}\"], globals()[f\"test_{dataset_name}\"] = load_data(dataset_name)\n",
        "\n",
        "# Check the results\n",
        "print(\"Specificity Train Data:\")\n",
        "print(train_climate_specificity.head())\n",
        "\n",
        "print(\"\\nSentiment Test Data:\")\n",
        "print(test_climate_sentiment.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0lEhY-ANUHq",
        "outputId": "6cbd712a-efb1-4b1a-d2af-6d8247a40554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specificity Train Data:\n",
            "                                                text  label\n",
            "0  − Scope 3: Optional scope that includes indire...      1\n",
            "1  The Group is not aware of any noise pollution ...      0\n",
            "2  Global climate change could exacerbate certain...      0\n",
            "3  Setting an investment horizon is part and parc...      0\n",
            "4  Climate change the physical impacts of climate...      0\n",
            "\n",
            "Sentiment Test Data:\n",
            "                                                text  label\n",
            "0  Sustainable strategy ‘red lines’ For our susta...      0\n",
            "1  Verizon’s environmental, health and safety man...      1\n",
            "2  In 2019, the Company closed a series of transa...      1\n",
            "3  In December 2020, the AUC approved the Electri...      0\n",
            "4  Finally, there is a reputational risk linked t...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Tokenizer"
      ],
      "metadata": {
        "id": "D1l_BGLNQQUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the tokenizer for bert-base-uncased\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "metadata": {
        "id": "dBbTq3cFO_rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Data so fit for BERT"
      ],
      "metadata": {
        "id": "oZLQB2nCQm3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df, text_column, label_column, max_length=512):\n",
        "    # Tokenize the text column\n",
        "    encodings = tokenizer(\n",
        "        df[text_column].tolist(),  # Texts to tokenize\n",
        "        truncation=True,          # Truncate text to max_length\n",
        "        padding=True,             # Pad shorter sequences\n",
        "        max_length=max_length,    # Maximum sequence length\n",
        "        return_tensors=\"pt\"       # Return PyTorch tensors\n",
        "    )\n",
        "\n",
        "    # Extract labels\n",
        "    labels = df[label_column].tolist()\n",
        "\n",
        "    return encodings, labels"
      ],
      "metadata": {
        "id": "B44mSGLgQpE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess climate specificity dataset"
      ],
      "metadata": {
        "id": "QUE_CvRHQtOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_data = {}\n",
        "\n",
        "for dataset_name in datasets.keys():\n",
        "    train_df = globals()[f\"train_{dataset_name}\"]\n",
        "    test_df = globals()[f\"test_{dataset_name}\"]\n",
        "\n",
        "    train_encodings, train_labels = preprocess_data(train_df, text_column=\"text\", label_column=\"label\")\n",
        "    test_encodings, test_labels = preprocess_data(test_df, text_column=\"text\", label_column=\"label\")\n",
        "\n",
        "    # Save the preprocessed data in a dictionary\n",
        "    preprocessed_data[dataset_name] = {\n",
        "        \"train\": (train_encodings, train_labels),\n",
        "        \"test\": (test_encodings, test_labels)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "47pWie4WRJ5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch necessary for training\n"
      ],
      "metadata": {
        "id": "xxUtmh9ISgo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ClimateDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return encodings and labels for a single data point\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n"
      ],
      "metadata": {
        "id": "hVp7vfeeShJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenized Data and labels into ClimateDataset\n"
      ],
      "metadata": {
        "id": "I92vZfgOUAYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloaders = {}\n",
        "\n",
        "for dataset_name, splits in preprocessed_data.items():\n",
        "    train_encodings, train_labels = splits[\"train\"]\n",
        "    test_encodings, test_labels = splits[\"test\"]\n",
        "\n",
        "    train_dataset = ClimateDataset(train_encodings, train_labels)\n",
        "    test_dataset = ClimateDataset(test_encodings, test_labels)\n",
        "\n",
        "    dataloaders[dataset_name] = {\n",
        "        \"train\": DataLoader(train_dataset, batch_size=16, shuffle=True),\n",
        "        \"test\": DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "4s83n4C-UAs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing the model\n"
      ],
      "metadata": {
        "id": "ItrTrEHNU6vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load BERT model for binary classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkGZ_oXWUk0n",
        "outputId": "8fdd089d-fa9b-4ebc-b7d9-a0eab47781df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define and optimize loss function"
      ],
      "metadata": {
        "id": "oPmRt-o-VJHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "84sE4CxSVEcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CPU or GPU?"
      ],
      "metadata": {
        "id": "8eFbG3BTW1Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "TkM-u31IW2iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop for one Dataset"
      ],
      "metadata": {
        "id": "qTSjxLkUXIC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, optimizer, train_loader, test_loader, device, epochs=3):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            # Move batch to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        accuracy = correct / len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch + 1}: Loss = {total_loss:.4f}, Accuracy = {accuracy:.4f}\")\n",
        "\n",
        "    # Evaluate the model after training\n",
        "    evaluate_model(model, test_loader, device)\n"
      ],
      "metadata": {
        "id": "zJZFNqckXIWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation function"
      ],
      "metadata": {
        "id": "GoGazbETXNNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            # Move batch to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / len(test_loader.dataset)\n",
        "    print(f\"Test Loss = {total_loss:.4f}, Test Accuracy = {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "hSv2r7-JXTKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training for each Dataset"
      ],
      "metadata": {
        "id": "xD_hPg9sXZjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from transformers import BertForSequenceClassification, AdamW\n",
        "from datetime import datetime\n",
        "\n",
        "for dataset_name, loaders in dataloaders.items():\n",
        "    print(f\"Training on {dataset_name} dataset...\")\n",
        "\n",
        "    # Load dataloaders\n",
        "    train_loader = loaders[\"train\"]\n",
        "    test_loader = loaders[\"test\"]\n",
        "\n",
        "    # Dynamically set `num_labels` based on the dataset\n",
        "    num_labels = 3 if dataset_name == \"climate_sentiment\" else 2\n",
        "\n",
        "    # Reload the model with the correct number of labels\n",
        "    try:\n",
        "        model = BertForSequenceClassification.from_pretrained(\n",
        "            \"bert-base-uncased\", num_labels=num_labels\n",
        "        )\n",
        "        optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "        model.to(device)\n",
        "\n",
        "        # Train the model\n",
        "        print(f\"Started training on {dataset_name} at {datetime.now()}\")\n",
        "        train_model(model, optimizer, train_loader, test_loader, device, epochs=3)\n",
        "\n",
        "        # Save the model for the specific dataset\n",
        "        save_path = f\"/content/drive/MyDrive/Big Data Project/NLP analysis/{dataset_name}_model\"\n",
        "        model.save_pretrained(save_path)\n",
        "        print(f\"Model for {dataset_name} saved at {save_path}!\")\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error during training on {dataset_name}: {e}\")\n",
        "        torch.cuda.empty_cache()  # Clear memory and continue\n",
        "        continue\n",
        "\n",
        "    # Free memory after training on the current dataset\n",
        "    del train_loader, test_loader\n",
        "    del model, optimizer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Training completed for all datasets.\")\n"
      ],
      "metadata": {
        "id": "vJbgnofcXZ0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model implementation"
      ],
      "metadata": {
        "id": "NCGQEefEXjkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qoU4o9m7dQzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "base_model = \"bert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "model_dir = \"/content/drive/MyDrive/Big Data Project/NLP analysis/climate_sentiment_model\"\n",
        "tokenizer.save_pretrained(model_dir)\n"
      ],
      "metadata": {
        "id": "aTW8wrPnFPUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format to JSON"
      ],
      "metadata": {
        "id": "f1BalthYlMgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Big Data Project/NLP analysis/Extracted Text\"\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "    if os.path.isfile(file_path) and filename.endswith(\".txt\"):\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            content = file.read()\n",
        "\n",
        "            json_filename = filename.replace(\".txt\", \".json\")\n",
        "            json_file_path = os.path.join(folder_path, json_filename)\n",
        "\n",
        "            with open(json_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "                json.dump({\"content\": content}, json_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"Alle TXT-Dateien wurden erfolgreich in JSON-Dateien umgewandelt.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7W8B_2TPt25",
        "outputId": "4fafb7c1-a623-49c6-8bec-837dd91585e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alle TXT-Dateien wurden erfolgreich in JSON-Dateien umgewandelt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment score"
      ],
      "metadata": {
        "id": "U3l4uICZdqfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Nutze Gerät: {device}\")\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Pfade zu den extrahierten Texten und dem Modell\n",
        "text_folder = '/content/drive/MyDrive/Big Data Project/NLP analysis/Extracted Text'\n",
        "model_dir = \"/content/drive/MyDrive/Big Data Project/NLP analysis/climate_sentiment_model\"\n",
        "\n",
        "# Modell und Tokenizer laden\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_dir).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw7Bmc9_Ho4G",
        "outputId": "1abfe6a3-ecfc-4a18-ad44-e0811faca3ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nutze Gerät: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label mapping"
      ],
      "metadata": {
        "id": "b_5mqVhwlda3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = os.path.join(model_dir, \"config.json\")\n",
        "with open(config_path, \"r\") as f:\n",
        "    config = json.load(f)\n",
        "label_mapping = config.get(\"id2label\", {})\n",
        "\n",
        "print(f\"Geladene Labels: {label_mapping}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-sM0NhIHz0Q",
        "outputId": "1e9fb904-4cf0-4a6d-bb4b-d089e9ab9872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geladene Labels: {'0': 'LABEL_0', '1': 'LABEL_1', '2': 'LABEL_2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis and Prediction"
      ],
      "metadata": {
        "id": "AB9NOIDsl-jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_label(segment):\n",
        "    \"\"\"Label und Wahrscheinlichkeiten für ein Segment vorhersagen\"\"\"\n",
        "    inputs = tokenizer(segment, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
        "\n",
        "    # Vorhersageklasse und Wahrscheinlichkeiten\n",
        "    predicted_class = int(torch.argmax(logits, dim=1).item())\n",
        "\n",
        "    # Mapping der Labels: 0 -> 0 (neutral), 1 -> -1 (risk), 2 -> 1 (opportunity)\n",
        "    label_mapping = {0: 0, 1: -1, 2: 1}\n",
        "    mapped_label = label_mapping[predicted_class]\n",
        "\n",
        "    return mapped_label, probabilities\n",
        "\n",
        "def analyze_file(file_path):\n",
        "    \"\"\"JSON-Datei analysieren, Absätze auswerten und einen Gesamtindex berechnen\"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "        text = data.get(\"content\", \"\")\n",
        "\n",
        "    # Text in Paragraphen splitten\n",
        "    segments = split_text_into_segments(text)\n",
        "\n",
        "    segment_results = []\n",
        "    for segment in segments:\n",
        "        label, probabilities = predict_label(segment)\n",
        "        segment_results.append({\"segment\": segment, \"label\": label, \"probabilities\": probabilities})\n",
        "\n",
        "    # Gesamtindex berechnen: Mittelwert der gemappten Labels\n",
        "    overall_index = sum(r[\"label\"] for r in segment_results) / len(segment_results)\n",
        "    return overall_index, segment_results\n",
        "\n",
        "# Verzeichnis mit JSON-Dateien\n",
        "text_folder = \"/content/drive/MyDrive/Big Data Project/NLP analysis/Extracted Text\"\n",
        "results = {}\n",
        "\n",
        "# Alle Dateien im Verzeichnis analysieren\n",
        "for filename in os.listdir(text_folder):\n",
        "    file_path = os.path.join(text_folder, filename)\n",
        "    if os.path.isfile(file_path) and filename.endswith(\".json\"):\n",
        "        overall_index, segment_results = analyze_file(file_path)\n",
        "        results[filename] = {\"overall_index\": overall_index, \"segment_results\": segment_results}\n",
        "\n",
        "# Ergebnisse ausgeben\n",
        "for file, result in results.items():\n",
        "    print(f\"{file}: Overall Index = {result['overall_index']:.2f}\")\n",
        "    for i, segment_result in enumerate(result[\"segment_results\"]):\n",
        "        print(f\"  Segment {i + 1}: Label = {segment_result['label']}, Probabilities = {segment_result['probabilities']}\")"
      ],
      "metadata": {
        "id": "lOksCTvMU-iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save results"
      ],
      "metadata": {
        "id": "StHa_aVZJD-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import re\n",
        "\n",
        "csv_file_path = \"/content/drive/MyDrive/Big Data Project/NLP analysis/sentiment_results.csv\"\n",
        "\n",
        "sorted_results = sorted(\n",
        "    filtered_results.items(),\n",
        "    key=lambda x: tuple(map(int, re.match(r'^(\\d+)\\.(\\d+)', x[0]).groups())) if re.match(r'^(\\d+)\\.(\\d+)', x[0]) else (float('inf'), float('inf'))\n",
        ")\n",
        "\n",
        "# Verzeichnis erstellen, falls nicht vorhanden\n",
        "os.makedirs(os.path.dirname(csv_file_path), exist_ok=True)\n",
        "\n",
        "# Ergebnisse in der CSV-Datei speichern\n",
        "with open(csv_file_path, mode='w', encoding='utf-8', newline='') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow([\"Filename\", \"Overall Index\"])  # Kopfzeile schreiben\n",
        "\n",
        "    # Sortierte Ergebnisse in die CSV schreiben, Score multiplizieren\n",
        "    for file, result in sorted_results:\n",
        "        final_score = result['overall_index'] * 5\n",
        "        writer.writerow([file, final_score])"
      ],
      "metadata": {
        "id": "oJe_QqVrJDk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commitment Score"
      ],
      "metadata": {
        "id": "MFu_foLNdu4O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hpnzlRK-dy9s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}